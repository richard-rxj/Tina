#!/usr/bin/env python# encoding: utf-8from Twitter.twitter_util import TweetCommonUtilfrom Twitter.tweet_tweetapi import TweetApiHelperfrom Twitter.tweet_tweepy import TweepyHelperclass TweetMain:    # TODO: to remove    # def get_tweets_tweetAPI(tweet_name):    #     tweets = []    #     next_token = None    #     i = 0    #     rule = gen_rule_payload("from:" + tweet_name    #                             , from_date="2006-03-21"  # UTC 2017-09-01 00:00    #                             # ,to_date="2017-10-30" #UTC 2017-10-30 00:00    #                             # ,results_per_call=100    #                             )    #     rs = ResultStream(**search_args, rule_payload=rule)    #     while True:    #         tweets.extend(list(rs.stream()))    #         rs.total_results = 0    #         next_token = rs.next_token    #         i = i + 1    #         if (next_token is None or i >= 10):    #             break    #     return tweets    def analyze(output_file_name, input_file_name, tweet_column_index):        input_user_infos = TweetCommonUtil.read_info_from_csv(input_file_name, tweet_column_index)        existing_user_infos_in_output = TweetCommonUtil.read_info_from_csv(output_file_name, tweet_column_index)        print("-------")        if (len(existing_user_infos_in_output) <= 0):            title = ["handID", "CONAME", "gvkey", "Company_twitter", "Company_type", "Company_twitter_month",                     "Company_twitter_day", "Company_twitter_year", "Company_twitter_date",                     "TWITTER_ACCOUNT_ID", "Number_follower", "Number_following",                     "Tweet_id_str", "Tweet_time", "Tweet_text", "likes", "retweets", "Is a reply", "reply_tweet_id",                     "reply_tweet_text", "Is a retweet", "retweet_tweet_id", "Is a quote", "quote_tweet_id"]            TweetCommonUtil.to_csv(title, output_file_name, False)        total = len(input_user_infos)        index = len(existing_user_infos_in_output)        for screen_name in input_user_infos.keys():            if screen_name in existing_user_infos_in_output:                continue            index = index + 1            print(str(total) + "-" + str(index) + "_" + screen_name)            origin_input_info = input_user_infos[screen_name]            tweet_account_info = TweepyHelper.get_tweet_info(screen_name)            account_only = False            if (len(tweet_account_info) > 1):                # all_tweets=get_alltweets_by_user(api,screen_name)                all_tweets = TweetApiHelper.get_tweets_tweetAPI(screen_name)                if len(all_tweets) < 1:                    account_only = True                else:                    for single_tweet in all_tweets:                        to_output = []                        to_output.extend(origin_input_info)                        to_output.extend(tweet_account_info)                        to_output.extend(single_tweet)                        TweetCommonUtil.to_csv(to_output, output_file_name, True)            else:                account_only = True            if account_only:                to_output = []                to_output.extend(origin_input_info)                to_output.extend(tweet_account_info)                TweetCommonUtil.to_csv(to_output, output_file_name, True)    def generate_powertrack_rulefile(output_file_name, input_file_name, tweet_column_index):        input_user_infos = TweetCommonUtil.read_info_from_csv(input_file_name, tweet_column_index)        TweetApiHelper.generate_powertrack_rule(input_user_infos.keys(), output_file_name)if __name__ == '__main__':    output_file_name = "201901_output.csv"    input_file_name = "20180226_input.csv"    tweet_column_index = 3    # analyze(output_file_name, input_file_name, tweet_column_index)    TweetMain.generate_powertrack_rulefile("rule_tina_uq.json",input_file_name,tweet_column_index)